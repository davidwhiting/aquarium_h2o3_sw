{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License \n",
    "\n",
    "Copyright 2019 Patrick Hall, Navdeep Gill, and the H2O.ai team\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "**DISCLAIMER:** This notebook is not legal compliance advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Decision Tree Model, Shapley Feature Importance, and LIME Reason Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python imports\n",
    "In general, NumPy and Pandas will be used for data manipulation purposes and H2o and scikit-learn will be used for modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn for single DT\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator # for LIME\n",
    "\n",
    "import numpy as np   # array, vector, matrix calculations\n",
    "import pandas as pd  # DataFrame handling\n",
    "\n",
    "pd.options.display.max_columns = 999 # enable display of all columns in notebook\n",
    "\n",
    "import shap # Python Shapley value package\n",
    "\n",
    "# system packages for calling external graphviz processes\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "import operator # for sorting dictionaries\n",
    "\n",
    "# in-notebook display\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, explore, and prepare UCI credit card default data\n",
    "\n",
    "UCI credit card default data: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "The UCI credit card default data contains demographic and payment information about credit card customers in Taiwan in the year 2005. The data set contains 23 input variables: \n",
    "\n",
    "* **`LIMIT_BAL`**: Amount of given credit (NT dollar)\n",
    "* **`SEX`**: 1 = male; 2 = female\n",
    "* **`EDUCATION`**: 1 = graduate school; 2 = university; 3 = high school; 4 = others \n",
    "* **`MARRIAGE`**: 1 = married; 2 = single; 3 = others\n",
    "* **`AGE`**: Age in years \n",
    "* **`PAY_0`, `PAY_2` - `PAY_6`**: History of past payment; `PAY_0` = the repayment status in September, 2005; `PAY_2` = the repayment status in August, 2005; ...; `PAY_6` = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; ...; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "* **`BILL_AMT1` - `BILL_AMT6`**: Amount of bill statement (NT dollar). `BILL_AMNT1` = amount of bill statement in September, 2005; `BILL_AMT2` = amount of bill statement in August, 2005; ...; `BILL_AMT6` = amount of bill statement in April, 2005. \n",
    "* **`PAY_AMT1` - `PAY_AMT6`**: Amount of previous payment (NT dollar). `PAY_AMT1` = amount paid in September, 2005; `PAY_AMT2` = amount paid in August, 2005; ...; `PAY_AMT6` = amount paid in April, 2005. \n",
    "\n",
    "These input variables are used to predict the target variable, whether or not a customer defaulted on their credit card bill in late 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XLS file\n",
    "path = 'default_of_credit_card_clients.xls'\n",
    "data = pd.read_excel(path,\n",
    "                     skiprows=1)\n",
    "\n",
    "# remove spaces from target column name \n",
    "data = data.rename(columns={'default payment next month': 'DEFAULT_NEXT_MONTH'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign modeling roles\n",
    "The shorthand name y is assigned to the prediction target. X is assigned to all other input variables in the credit card default data except the row indentifier, ID, and the demographic variables are dropped from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target and inputs for decision tree\n",
    "y = 'DEFAULT_NEXT_MONTH'\n",
    "X = [name for name in data.columns if name not in [y, 'ID', 'AGE', 'EDUCATION', 'SEX', 'MARRIAGE', 'LIMIT_BAL']]\n",
    "print('y =', y)\n",
    "print('X =', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test sets for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345) # set random seed for reproducibility\n",
    "split_ratio = 0.7     # 70%/30% train/test split\n",
    "\n",
    "# execute split\n",
    "split = np.random.rand(len(data)) < split_ratio\n",
    "train = data[split]\n",
    "test = data[~split]\n",
    "\n",
    "# summarize split\n",
    "print('Train data rows = %d, columns = %d' % (train.shape[0], train.shape[1]))\n",
    "print('Test data rows = %d, columns = %d' % (test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Single Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train decision tree classifier\n",
    "Several different depths were assesed on validation data and these hyperparameters performed well enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=12345, max_depth=3)\n",
    "clf.fit(train[X].values, train[y].values)\n",
    "sklearn.tree.export_graphviz(clf, 'model.gv', feature_names=X, proportion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test[y].values, clf.predict_proba(test[X].values)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PNG from GraphViz dot file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct call to generate PNG from \n",
    "# graphviz representation of the tree\n",
    "png_args = str('dot -Tpng model.gv -o model.png')\n",
    "png_args = png_args.split()\n",
    "\n",
    "# call\n",
    "print('Calling external process ...')\n",
    "print(' '.join(png_args))\n",
    "_ = subprocess.call(png_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Explain Single Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display tree\n",
    "This is the entire model, displayed as a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display in-notebook\n",
    "display(Image(('model.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display global Shapley variable importance\n",
    "Shapley values are a locally-accurate and globally consistent variable importance metric. Instead of relying on traditional single-value variable importance measures, local Shapley values for each input will be calculated and aggregated below to get a more holistic and consisent measurement for the global importance of each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(clf, test[X], model_output='probability', feature_dependence='independent')\n",
    "shap_values = explainer.shap_values(test[X].values)\n",
    "shap.summary_plot(shap_values[1], X, plot_type='bar', color='royalblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find riskiest customer\n",
    "The riskiest customer in this data set is selected from all the customers who have a probability of default of ~0.77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "yhat = 'p_DEFAULT_NEXT_MONTH'\n",
    "test[yhat] = clf.predict_proba(test[X].values)[:, 1]\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "test.sort_values(by=yhat, inplace=True)\n",
    "id_ = test.iloc[-1, :].loc['ID']\n",
    "idx = test.iloc[-1, :].name\n",
    "pd.DataFrame(test.iloc[-1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display local Shapley values for the riskiest customer predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = pd.DataFrame(shap_values[1][idx, :], index=X)\n",
    "s_df.sort_values(by=0, inplace=True)\n",
    "_ = s_df[s_df[0] != 0].plot(kind='barh' , color='royalblue', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapley values combine the customer's data values, the rules of the displayed decision tree, and crucially, the rules of many similar perturbed decision trees to create locally accurate and globally consistent feature importance values for each customer in the dataset. Note that these values consider variables *not* on the customer's decision path. This is because Shapley values take other encodings of the signal in the dataset into account when creating local feature importance. Shapley values are one the few explanation methods that account for the so-called Rashomon effect in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Shapley sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the Shapley values are locally accurate. i.e. they sum to the model prediction for this customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df.sum()[0] + explainer.expected_value[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximate LIME trends\n",
    "LIME uses linear models fit to a more complex machine learning function to explain that machine learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select riskiest customers, those who are more than 1 month late on their most recent payment\n",
    "local = test[(test['PAY_0'] > 1.5)] \n",
    "\n",
    "# variables with non-zero Global Shapley importance\n",
    "local_X = s_df[s_df[0] != 0].index\n",
    "\n",
    "h2o.init() # use h2o to train a linear model in the region of interest\n",
    "\n",
    "# convert data into H2o frame\n",
    "# treat categorical variables as such\n",
    "local = h2o.H2OFrame(local)\n",
    "local['PAY_0'] = local['PAY_0'].asfactor()\n",
    "local['PAY_2'] = local['PAY_2'].asfactor()\n",
    "local['PAY_5'] = local['PAY_5'].asfactor()\n",
    "local['PAY_6'] = local['PAY_6'].asfactor()\n",
    "\n",
    "# initialize\n",
    "local_glm = H2OGeneralizedLinearEstimator(lambda_search=True, seed=12345)\n",
    "\n",
    "# train \n",
    "local_glm.train(x=list(local_X), y=yhat, training_frame=local)\n",
    "\n",
    "# coefs\n",
    "print('\\nLocal GLM Coefficients:')\n",
    "for c_name, c_val in sorted(local_glm.coef().items(), key=operator.itemgetter(1)):\n",
    "    if c_val != 0.0:\n",
    "        print('%s %s' % (str(c_name + ':').ljust(25), c_val))\n",
    "        \n",
    "# r2\n",
    "print('\\nLocal GLM R-square:\\n%.6f' % local_glm.r2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the intercept of these LIMEs is logical and the LIMEs have a good R<sup>2</sup>, this information can be taken as a rough, linear description of the tree model's response surface in the region of interest, i.e. an average description for risky customers under the model.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess LIME prediction accuracy for row of interest\n",
    "It can also be seen that the LIMES have very good local accuracy for the riskiest customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_glm.predict(local[local['ID'] == id_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visually assess LIME model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranked predictions plot\n",
    "pred_frame = local_glm.predict(local).cbind(local)\\\n",
    "                       .as_data_frame()[['predict', yhat]]\n",
    "pred_frame.columns = ['LIME Preds.', 'DT Preds.']\n",
    "pred_frame.sort_values(by='DT Preds.', inplace=True)\n",
    "pred_frame.reset_index(inplace=True, drop=True)\n",
    "_ = pred_frame.plot(title='DT vs. LIME Ranked Predictions Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ranked predictions plot shows that the LIMEs follows the decision tree predictions for the most part and provides more evidence that the LIMES have decent fidelity to the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Pairing a directly interpretable model and Shapley values enabled visualization of an entire predictive model and accurate local feature importance values for any individual in the model. Combining Shapley values and LIME allows for comparison of the average behavior of customers in a region of interest and anyone single customer in the dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
