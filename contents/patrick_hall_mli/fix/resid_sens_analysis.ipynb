{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License \n",
    "\n",
    "Copyright 2017 - 2019 Patrick Hall and the H2O.ai team\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "**DISCLAIMER:** This notebook is not legal compliance advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing machine learning models for accuracy, trustworthiness, and stability with Python and H2O\n",
    "#### Performing residual analysis and sensitivity analysis to validate complex models\n",
    "\n",
    "This notebook provides a basic introduction to two traditional data analysis and model diagnostic techniques that can be applied to machine learning models: residual analysis and sensitivity analysis. The notebook starts by loading the UCI credit card default dataset and using h2o to train a GBM model to predict credit card defaults. Then, residual analysis is used to discover and debug an issue with the GBM, and the GBM is retrained and improved. The notebook concludes by conducting sensitivity analysis to test the GBM credit card default model for fairness and stability. \n",
    "\n",
    "#### Start H2O cluster\n",
    "\n",
    ">_**Note**: The `os.system` command below is used solely for the H2O Aquarium training platform._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('/home/h2o/bin/startup')\n",
    "!sleep 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python imports\n",
    "In general, NumPy and Pandas will be used for data manipulation purposes and h2o will be used for modeling tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2o Python API with specific classes\n",
    "import h2o \n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "import numpy as np   # array, vector, matrix calculations\n",
    "import pandas as pd  # DataFrame handling\n",
    "\n",
    "pd.options.display.max_columns = 999 # enable display of all columns in notebook\n",
    "\n",
    "# plotting functionality\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# display plots in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start h2o\n",
    "H2o is both a library and a server. The machine learning algorithms in the library take advantage of the multithreaded and distributed architecture provided by the server to train machine learning algorithms extremely efficiently. The API for the library was imported above in cell 2, but the server still needs to be started.\n",
    "\n",
    ">The parameters used in `h2o.init` will depend on your specific environment. In particular, the\n",
    ">```\n",
    ">url='http://localhost:54321/h2o'\n",
    ">```\n",
    ">command below is required only in aquarium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init(url='http://localhost:54321/h2o', max_mem_size='2G')\n",
    "h2o.remove_all()    # remove any existing data structures from h2o memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download, explore, and prepare UCI credit card default data\n",
    "\n",
    "UCI credit card default data: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "The UCI credit card default data contains demographic and payment information about credit card customers in Taiwan in the year 2005. The data set contains 23 input variables: \n",
    "\n",
    "* **`LIMIT_BAL`**: Amount of given credit (NT dollar)\n",
    "* **`SEX`**: 1 = male; 2 = female\n",
    "* **`EDUCATION`**: 1 = graduate school; 2 = university; 3 = high school; 4 = others \n",
    "* **`MARRIAGE`**: 1 = married; 2 = single; 3 = others\n",
    "* **`AGE`**: Age in years \n",
    "* **`PAY_0`, `PAY_2` - `PAY_6`**: History of past payment; `PAY_0` = the repayment status in September, 2005; `PAY_2` = the repayment status in August, 2005; ...; `PAY_6` = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; ...; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "* **`BILL_AMT1` - `BILL_AMT6`**: Amount of bill statement (NT dollar). `BILL_AMNT1` = amount of bill statement in September, 2005; `BILL_AMT2` = amount of bill statement in August, 2005; ...; `BILL_AMT6` = amount of bill statement in April, 2005. \n",
    "* **`PAY_AMT1` - `PAY_AMT6`**: Amount of previous payment (NT dollar). `PAY_AMT1` = amount paid in September, 2005; `PAY_AMT2` = amount paid in August, 2005; ...; `PAY_AMT6` = amount paid in April, 2005. \n",
    "\n",
    "These 23 input variables are used to predict the target variable, whether or not a customer defaulted on their credit card bill in late 2005.\n",
    "\n",
    "Because h2o accepts both numeric and character inputs, some variables will be recoded into more transparent character values.\n",
    "\n",
    "#### Import data and clean\n",
    "The credit card default data is available as an `.xls` file. Pandas reads `.xls` files automatically, so it's used to load the credit card default data and give the prediction target a shorter name: `DEFAULT_NEXT_MONTH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import XLS file\n",
    "path = 'default_of_credit_card_clients.xls'\n",
    "data = pd.read_excel(path,\n",
    "                     skiprows=1)\n",
    "\n",
    "# remove spaces from target column name \n",
    "data = data.rename(columns={'default payment next month': 'DEFAULT_NEXT_MONTH'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign modeling roles\n",
    "The shorthand name `y` is assigned to the prediction target. `X` is assigned to all other input variables in the credit card default data except the row indentifier, `ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target and inputs for GBM\n",
    "y = 'DEFAULT_NEXT_MONTH'\n",
    "X = [name for name in data.columns if name not in [y, 'ID']]\n",
    "print('y =', y)\n",
    "print('X =', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function for recoding values in the UCI credict card default data\n",
    "This simple function maps longer, more understandable character string values from the UCI credit card default data dictionary to the original integer values of the input variables found in the dataset. These character values can be used directly in h2o decision tree models, and the function returns the original Pandas DataFrame as an h2o object, an H2OFrame. H2o models cannot run on Pandas DataFrames. They require H2OFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_cc_data(frame):\n",
    "    \n",
    "    \"\"\" Recodes numeric categorical variables into categorical character variables\n",
    "    with more transparent values. \n",
    "    \n",
    "    Args:\n",
    "        frame: Pandas DataFrame version of UCI credit card default data.\n",
    "        \n",
    "    Returns: \n",
    "        H2OFrame with recoded values.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # define recoded values\n",
    "    sex_dict = {1:'male', 2:'female'}\n",
    "    education_dict = {0:'other', 1:'graduate school', 2:'university', 3:'high school', \n",
    "                      4:'other', 5:'other', 6:'other'}\n",
    "    marriage_dict = {0:'other', 1:'married', 2:'single', 3:'divorced'}\n",
    "    pay_dict = {-2:'no consumption', -1:'pay duly', 0:'use of revolving credit', 1:'1 month delay', \n",
    "                2:'2 month delay', 3:'3 month delay', 4:'4 month delay', 5:'5 month delay', 6:'6 month delay', \n",
    "                7:'7 month delay', 8:'8 month delay', 9:'9+ month delay'}\n",
    "    \n",
    "    # recode values using Pandas apply() and anonymous function\n",
    "    frame['SEX'] = frame['SEX'].apply(lambda i: sex_dict[i])\n",
    "    frame['EDUCATION'] = frame['EDUCATION'].apply(lambda i: education_dict[i])    \n",
    "    frame['MARRIAGE'] = frame['MARRIAGE'].apply(lambda i: marriage_dict[i]) \n",
    "    for name in frame.columns:\n",
    "        if name in ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']:\n",
    "            frame[name] = frame[name].apply(lambda i: pay_dict[i])            \n",
    "                \n",
    "    return h2o.H2OFrame(frame)\n",
    "\n",
    "data = recode_cc_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure target is handled as a categorical variable\n",
    "In h2o, a numeric variable can be treated as numeric or categorical. The target variable `DEFAULT_NEXT_MONTH` takes on values of `0` or `1`. To ensure this numeric variable is treated as a categorical variable, the `asfactor()` function is used to explicitly declare that it is a categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[y] = data[y].asfactor() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display descriptive statistics\n",
    "The h2o `describe()` function displays a brief description of the credit card default data. For the categorical input variables `LIMIT_BAL`, `SEX`, `EDUCATION`, `MARRIAGE`, and `PAY_0`-`PAY_6`, the new character values created above in cell 5 are visible. Basic descriptive statistics are displayed for numeric inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train an H2O GBM classifier\n",
    "\n",
    "#### Split data into training and test sets for early stopping\n",
    "The credit card default data is split into training and test sets to monitor and prevent overtraining. Reproducibility is also important factor in creating trustworthy models, and randomly splitting datasets can introduce randomness in model predictions and other results. A random seed is used here to ensure the data split is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation\n",
    "train, test = data.split_frame([0.7], seed=12345)\n",
    "\n",
    "# summarize split\n",
    "print('Train data rows = %d, columns = %d' % (train.shape[0], train.shape[1]))\n",
    "print('Test data rows = %d, columns = %d' % (test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train h2o GBM classifier\n",
    "Many tuning parameters must be specified to train a GBM using h2o. Typically a grid search would be performed to identify the best parameters for a given modeling task using the `H2OGridSearch` class. For brevity's sake, a previously-discovered set of good tuning parameters are specified here. Because gradient boosting methods typically resample training data, an additional random seed is also specified for the h2o GBM using the `seed` parameter to create reproducible predictions, error rates, and variable importance values. To avoid overfitting, the `stopping_rounds` parameter is used to stop the training process after the test error fails to decrease for 5 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize GBM model\n",
    "model = H2OGradientBoostingEstimator(ntrees=150,            # maximum 150 trees in GBM\n",
    "                                     max_depth=4,           # trees can have maximum depth of 4\n",
    "                                     sample_rate=0.9,       # use 90% of rows in each iteration (tree)\n",
    "                                     col_sample_rate=0.9,   # use 90% of variables in each iteration (tree)\n",
    "                                     stopping_rounds=5,     # stop if validation error does not decrease for 5 iterations (trees)\n",
    "                                     seed=12345)            # for reproducibility\n",
    "\n",
    "# train a GBM model\n",
    "model.train(y=y, x=X, training_frame=train, validation_frame=test)\n",
    "\n",
    "# print AUC\n",
    "print('GBM Test AUC = %.4f' % model.auc(valid=True))\n",
    "\n",
    "# uncomment to see model details\n",
    "# print(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display variable importance\n",
    "During training, the h2o GBM aggregates the improvement in error caused by each split in each decision tree across all the decision trees in the ensemble classifier. These values are attributed to the input variable used in each split and give an indication of the contribution each input variable makes toward the model's predictions. The variable importance ranking should be parsimonious with human domain knowledge and reasonable expectations. In this case, a customer's most recent payment behavior, `PAY_0`, is by far the most important variable followed by their second most recent payment, `PAY_2`, their credit limit, `LIMIT_BAL`, and third most recent payment behavior, `PAY_3`. This result is well-aligned with business practices in credit lending: people who miss their most recent payments are likely to default soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conduct residual analysis to debug model\n",
    "Residuals refer to the difference between the recorded value of a dependent variable and the predicted value of a dependent variable for every row in a data set. Plotting the residual values against the predicted values is a time-honored model assessment technique and a great way to see all your modeling results in two dimensions.\n",
    "\n",
    "#### Bind model predictions onto test data \n",
    "To calculate the residuals for our GBM model, first the model predictions are merged onto onto the test set. The test data is used here to see how the model behaves on holdout data, which should be closer to its behavior on new data than analyzing residuals for the training inputs and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = 'p_DEFAULT_NEXT_MONTH'\n",
    "preds1 = model.predict(test).drop(['predict', 'p0'])\n",
    "preds1.columns = [yhat]\n",
    "test_yhat = test.cbind(preds1[yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate deviance residuals for binomial classification\n",
    "For binomial classification, deviance residuals are related to the logloss cost function. Like analyzing $y - \\hat{y}$ for linear regression, these residuals are the quantities that the GBM sought to minimize. Deviance residual values are calculated by applying the simple formula in the cell directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Pandas for adding columns and plotting\n",
    "test_yhat = test_yhat.as_data_frame()\n",
    "test_yhat['s'] = 1\n",
    "test_yhat.loc[test_yhat['DEFAULT_NEXT_MONTH'] == 0, 's'] = -1\n",
    "test_yhat['r_DEFAULT_NEXT_MONTH'] = test_yhat['s'] * np.sqrt(-2*(test_yhat[y]*np.log(test_yhat[yhat]) +\n",
    "                                                                 ((1 - test_yhat[y])*np.log(1 - test_yhat[yhat]))))\n",
    "test_yhat = test_yhat.drop('s', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot residuals\n",
    "Plotting residuals is a model debugging and diagnostic tool that enables users to see modeling results, and any anomolies, in a single two-dimensional plot. Here the green points represent customers who defaulted, and the blue points represent customers who did not. A few potential outliers are visible. There appear to be several cases in the test data with relatively large negative residuals. Understanding and addressing the factors that cause these outliers could lead to a more acccurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = test_yhat.groupby('DEFAULT_NEXT_MONTH') # define groups\n",
    "fig, ax_ = plt.subplots(figsize=(8, 8))          # initialize figure\n",
    "\n",
    "plt.xlabel('Predicted: DEFAULT_NEXT_MONTH')\n",
    "plt.ylabel('Residual: DEFAULT_NEXT_MONTH')\n",
    "\n",
    "# plot groups with appropriate color\n",
    "color_list = ['b', 'g'] \n",
    "c_idx = 0\n",
    "for name, group in groups:\n",
    "    ax_.plot(group.p_DEFAULT_NEXT_MONTH, group.r_DEFAULT_NEXT_MONTH, label=' '.join(['DEFAULT_NEXT_MONTH:', str(name)]),\n",
    "             marker='o', linestyle='', color=color_list[c_idx], alpha=0.3)\n",
    "    c_idx += 1\n",
    "\n",
    "_ = ax_.legend(loc=1) # legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort data by residuals and display data and residuals\n",
    "Printing a table with model inputs, actual target values, and model predictions sorted by residuals is another simple way to analyze residuals. Customers that defaulted, but were predicted not to, are listed at the top of the table below. Scroll to the bottom of the table to see the customers who were predicted to default, but then did not. Also notice the jumps in residual values between -1.96 and -1.99 and then again between -2.02 and -2.16. These are the potential outliers pictured in the residual plot above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_yhat = test_yhat.sort_values(by='r_DEFAULT_NEXT_MONTH', ascending=False).reset_index(drop=True)\n",
    "test_yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple analysis has uncovered some of the most difficult customers for the GBM to correctly predict default. Perhaps because of the high importance of the payment features, `PAY_0`-`PAY_6`, the GBM struggles to correctly predict several cases in which customers made timely recent payments and then suddenly defaulted (high positive residuals) and those customers that were chronically late making payments but did not default (high negative residuals).\n",
    "\n",
    "#### Plot residuals by most important input variable \n",
    "Residuals can also be plotted for important input variables to understand how the values of a single input variable affect prediction errors. When plotted by `PAY_0`, the residuals confirm that the GBM is struggling to accurately predict cases where default status is not correlated with recent payment behavior in an obvious way. The residual plots for values of `PAY_0` indicating timely payment behavior (e.g., `use of revolving credit`, `pay duly`, and `no consumption`) generally display the highest positive residuals and relatively small negative residuals. Residuals for the other values of `PAY_0`, those that represent late recent payments, tend to show large negative residuals and relatively small positive residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Seaborn FacetGrid for convenience\n",
    "g = sns.FacetGrid(test_yhat, row='PAY_0', hue=y)\n",
    "_ = g.map(plt.scatter, yhat, 'r_DEFAULT_NEXT_MONTH', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrain GBM classifier based on results of residual analysis\n",
    "Now that an issue has been discovered using residual analysis, can it be resolved? \n",
    "\n",
    "#### Create a feature that contains information about behavior over time\n",
    "One strategy to improve prediction accuracy is to introduce a new feature that summarizes a customer's spending behavior over time to expose any potential financial instability: the standard deviation of a customer's bill amounts over six months. Pandas has a one-liner for calculating standard deviations for a set of columns, so the H2OFrame is casted back into Pandas DataFrame for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.as_data_frame()\n",
    "data['bill_std'] = data[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].std(axis=1)\n",
    "data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Pandas DataFrame back to H2OFrame for modeling\n",
    "To retrain the model with the new feature, an H2OFrame is required and that H2OFrame is split using the same proportion and random seed as in cell 8 for the first GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h2o.H2OFrame(data)                          # convert \n",
    "data[y] = data[y].asfactor()                       # ensure target is handled as a categorical variable\n",
    "train, test = data.split_frame([0.7], seed=12345)  # split into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain GBM with new feature\n",
    "The `train()` function is used to retrain the GBM model with the nearly same hyperparameters used previously in cell 9. A slight, but noticable, increase in accuracy results from retraining with the new feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize GBM model\n",
    "model = H2OGradientBoostingEstimator(ntrees=150,            # maximum 150 trees in GBM\n",
    "                                     max_depth=6,           # trees can have maximum depth of 6\n",
    "                                     sample_rate=0.9,       # use 90% of rows in each iteration (tree)\n",
    "                                     col_sample_rate=0.85,  # use 90% of variables in each iteration (tree)\n",
    "                                     stopping_rounds=5,     # stop if validation error does not decrease for 5 iterations (trees)\n",
    "                                     seed=12345)            # for reproducibility\n",
    "\n",
    "# retrain GBM model\n",
    "model.train(y=y,\n",
    "            x=X + ['bill_std'], # add new feature\n",
    "            training_frame=train, \n",
    "            validation_frame=test)\n",
    "\n",
    "# print AUC\n",
    "print('GBM Test AUC = %.4f' % model.auc(valid=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there maybe be other more complex features or a more optimal set of hyperparameters that could lead to further incremental increases in accuracy, more information is needed to achieve meaningful improvement in prediction performance. In particular, a common measure for credit lending, the customers' debt-to-income ratio, for each payment and billing period could be particularly useful. Spikes in debt-to-income ratio, representing loss of income or large increases in debt, would likely be very indicative of a default and would expose the GBM to information not currently available in the UCI credit card default data. Introducing new data could also de-emphasize `PAY_0`, which would likely result in a more stable model as well.\n",
    "\n",
    "## 5. Perform sensitivity analysis to test model performance on unseen data\n",
    "\n",
    "Sensitivity analysis investigates whether model behavior and outputs remain stable when data is intentionally perturbed or other changes are simulated in data. Beyond traditional assessment practices, sensitivity analysis of machine learning model predictions is perhaps the most important validation technique for machine learning models. Machine learning models can make drastically differing predictions for only minor changes in input variable values. In practice, many linear model validation techniques focus on the numerical instability of regression parameters due to correlation between input variables or between input variables and the dependent variable. It may be prudent for those switching from linear modeling techniques to machine learning techniques to focus less on numerical instability of model parameters and to focus more on the potential instability of model predictions.\n",
    "\n",
    "Here sensitivity analysis is used to understand the impact of  changing the most important input variable, `PAY_0`, and the impact of a sociologically sensitive variable, `SEX`, in the model. If the model changes in reasonable and expected ways when important variable values are changed this can enhance trust in the model. If the contribution of potentially sensitive variables, such as those related to gender, race, age, marital status, or disability status, can be shown to have minimal impact on the model, this is an indication of fairness in the model predictions and can also increase overall trust in the model.\n",
    "\n",
    "#### Bind new model predictions onto test data \n",
    "Typically, a productive exercise in model debugging and validation is to investigate customers with very high or low predicted probabilities to determine if their predictions stay within reasonable bounds when important variables are changed. The predictions from the new, more accurate model are merged onto the test set to find these potentially interesting customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model.predict(test).drop(['predict', 'p0'])\n",
    "preds2.columns = [yhat]\n",
    "test_yhat = test.cbind(preds1[yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function for finding percentile indices\n",
    "The function below finds and returns the row indices for the minimum, the maximum, and the deciles of one column in terms of another -- in this case, the model predictions (`p_DEFAULT_NEXT_MONTH`) and the row identifier (`ID`), respectively. These indices are used as a starting point for boundary testing. Outlying predictions found through residual analysis is another group of potentially interesting local predictions to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile_dict(yhat, id_, frame):\n",
    "\n",
    "    \"\"\" Returns the minimum, the maximum, and the deciles of a column, yhat, \n",
    "        as the indices based on another column id_.\n",
    "    \n",
    "    Args:\n",
    "        yhat: Column in which to find percentiles.\n",
    "        id_: Id column that stores indices for percentiles of yhat.\n",
    "        frame: H2OFrame containing yhat and id_. \n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of percentile values and index column values.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create a copy of frame and sort it by yhat\n",
    "    sort_df = frame.as_data_frame()\n",
    "    sort_df.sort_values(yhat, inplace=True)\n",
    "    sort_df.reset_index(inplace=True)\n",
    "    \n",
    "    # find top and bottom percentiles\n",
    "    percentiles_dict = {}\n",
    "    percentiles_dict[0] = sort_df.loc[0, id_]\n",
    "    percentiles_dict[99] = sort_df.loc[sort_df.shape[0]-1, id_]\n",
    "\n",
    "    # find 10th-90th percentiles\n",
    "    inc = sort_df.shape[0]//10\n",
    "    for i in range(1, 10):\n",
    "        percentiles_dict[i * 10] = sort_df.loc[i * inc,  id_]\n",
    "\n",
    "    return percentiles_dict\n",
    "\n",
    "# display percentiles dictionary\n",
    "# ID values for rows\n",
    "# from lowest prediction \n",
    "# to highest prediction\n",
    "pred_percentile_dict = get_percentile_dict(yhat, 'ID', test_yhat)\n",
    "pred_percentile_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display test data prediction range\n",
    "Unlike some regression models and neural networks that can produce outrageous predictions for changes in input variables, GBM predictions in new data are bounded by the lowest and highest probability leaf nodes in each constiuent decision tree in the trained model. While unbounded, extreme predictions are typically not an issue for tree models and classification tasks, it is often a good idea to check that the model predictions cover a full range of useful values in the test set. Below, we can see that the model produces both very low and very high predictions in test set, indicating that it is likely responsive to signal in new data and not simply predicting the majority class or an average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lowest prediction:', test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])][[y, yhat]])\n",
    "print('Highest prediction:', test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])][[y, yhat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use trained model to test predictions for interesting situations: customer least likely to default\n",
    "As a starting point for further analysis, sensitivity analysis is performed for the customer least likely to default. This woman has a roughly 0.01 probability of defaulting according to the trained GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test effect of changing `SEX`\n",
    "\n",
    "`SEX` should not have a large impact on predictions. This could indicate unwanted sociological bias in the GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case = test_case.drop([yhat])\n",
    "test_case['SEX'] = 'male'\n",
    "test_case = test_case.cbind(model.predict(test_case))\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, simulating this person as a male does not have a large impact on their probability of default.\n",
    "\n",
    "#### Test effect of changing `PAY_0`\n",
    "\n",
    "Variable importance and residual analysis indicates that the value of `PAY_0` can have a strong effect on model predictions. Measuring the change in predicted probability when the value of `PAY_0` is changed from a timely payment to late payment is probably a good test case for prediction stability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[0])]\n",
    "test_case = test_case.drop([yhat])\n",
    "test_case['PAY_0'] = '2 month delay' \n",
    "test_case = test_case.cbind(model.predict(test_case))\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the value is changed from `no consumption` to `two month delay` there is a roughly 40X increase in predicted probability, but assuming a 0.5 probability cutoff, the predicted outcome is stable. However, such a marked change related to the value of one variable is problematic for numerous reasons.\n",
    "\n",
    "#### Use trained model to test predictions for interesting situations: customer most likely to default\n",
    "Now the same test will be performed on the customer most likely to default. This woman has an approximately 0.94 probability of default under the GBM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test effect of changing `SEX`\n",
    "Changing the value for `SEX` from female to male for this customer decreases the predicted probability to about 0.84, another relatively small change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case = test_case.drop([yhat])\n",
    "test_case['SEX'] = 'male'\n",
    "test_case = test_case.cbind(model.predict(test_case))\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test effect of changing `PAY_0`\n",
    "Switching the riskiest customer's value for `PAY_0` from `3 month delay` to `pay duly` reduces the their chance of defaulting from roughly 94% to roughly 73%, a noticable swing in probability but still a higher probability value, markedly greater than the typical 0.5 cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = test_yhat[test_yhat['ID'] == int(pred_percentile_dict[99])]\n",
    "test_case = test_case.drop([yhat])\n",
    "test_case['PAY_0'] = 'pay duly' \n",
    "test_case = test_case.cbind(model.predict(test_case))\n",
    "test_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this small number of boundary test cases, the GBM model appears stable. However, if large swings in predictions occur for sensitive or important variables, practicioners are urged to retrain unstable models without the problematic variables or combinations of variables, which may unfortunately involve some trial and error. Also, four test cases is woefully inadequate for real-world models. Automated sensitivity analysis across many variables, combinations of variables, and for many different rows of data seems more appropriate for mission-critical machine learning.\n",
    "\n",
    "#### Shutdown H2O\n",
    "After using h2o, it's typically best to shut it down. However, before doing so, users should ensure that they have saved any h2o data structures, such as models, H2OFrames, or scoring artifacts, such as POJOs or MOJOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful, this can erase your work!\n",
    "h2o.cluster().shutdown(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "In this notebook, a complex GBM classifier was trained to predict credit card defaults. Residual analysis was used to debug the GBM model predictions and enabled a slight improvement in accuracy. Sensitivity analysis was used to test the GBM for trustworthiness and stability. In a small number of boundary test cases, the trained GBM appeared stable. Residual analysis and sensitivity analysis are powerful model debugging techniques and can increase trust in complex models. These techniques should generalize well for many types of business and research problems, enabling you to train a complex model and justify it to your colleagues, bosses, and potentially, external regulators. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
